{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6d28f-f624-4274-8303-3cf785726200",
   "metadata": {},
   "outputs": [],
   "source": "# Import fast gradient descent"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6f06ddcbb22d8b43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "from art.defences.preprocessor import LabelSmoothing\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
    "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
    "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 10)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "\n",
    "# Step 1a: Swap axes to PyTorch's NCHW format\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "# Step 2: Apply Label Smoothing as a preprocessing defense\n",
    "label_smoothing = LabelSmoothing(max_value=1.0, apply_fit=True, apply_predict=False)\n",
    "_, y_train = label_smoothing(x_train, y_train)\n",
    "\n",
    "# Step 2: Create the model\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Step 2a: Define the loss function and the optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Step 4: Setup TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"./runs/mnist_training\")\n",
    "\n",
    "# Step 5: Train the ART classifier and log metrics to TensorBoard\n",
    "for epoch in range(5):  # number of epochs\n",
    "    classifier.fit(x_train, y_train, batch_size=64, nb_epochs=1)\n",
    "\n",
    "    # Log training accuracy and loss to TensorBoard\n",
    "    predictions_train = classifier.predict(x_train[:100])  # Predict on a small batch for monitoring\n",
    "    train_accuracy = np.sum(np.argmax(predictions_train, axis=1) == np.argmax(y_train[:100], axis=1)) / len(y_train[:100])\n",
    "\n",
    "    writer.add_scalar(\"Accuracy/train\", train_accuracy, epoch + 1)\n",
    "    writer.add_scalar(\"Loss/train\", criterion(model(torch.tensor(x_train[:100]).to(torch.float32)),\n",
    "                                               torch.tensor(np.argmax(y_train[:100], axis=1))).item(), epoch + 1)\n",
    "\n",
    "# Step 4a: Save the model after training\n",
    "torch.save(model.state_dict(), \"mnist_model-improved.pth\")\n",
    "\n",
    "# Step 6: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "\n",
    "# Log test accuracy to TensorBoard\n",
    "writer.add_scalar(\"Accuracy/test\", accuracy, 1)\n",
    "\n",
    "# Step 7: Create the FGSM attack\n",
    "epsilon = 0.1  # Define the perturbation strength\n",
    "attack = FastGradientMethod(estimator=classifier, eps=epsilon)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv = attack.generate(x=x_test)\n",
    "\n",
    "# Step 8: Evaluate the classifier on adversarial examples\n",
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "\n",
    "print(\"Accuracy on adversarial test examples (FGSM, epsilon={}): {}%\".format(epsilon, accuracy_adv * 100))\n",
    "\n",
    "# Log adversarial accuracy to TensorBoard\n",
    "writer.add_scalar(\"Accuracy/adversarial_test\", accuracy_adv, 1)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ],
   "id": "3e5675bb9c491dbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "89035900f6339895"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
